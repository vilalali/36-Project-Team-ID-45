# Backend of DFS Project

### Setup
- Create a .env file on root directory `dfs-backend/.env` with contents:
```bash
# APP PORT
PORT=3001

# ENVIRONMENT TYPE
ENV_TYPE=test  # local, dev, qa, prod, test

# ENVIRONMENT ADDRESS
BASE_URL_DEV="http://datafoundation-dev.iiit.ac.in"
BASE_URL_QA="https://datafoundation-qa.iiit.ac.in"
BASE_URL_PROD="https://datafoundation.iiit.ac.in"
BASE_URL_LOCAL="http://localhost:3002"
BASE_URL_TEST="http://localhost:3002"
FRONTEND_URL="http://localhost:3000"

# Database Configuration
DB_NAME="dfsdata_v2"
DB_USER="dfs"
DB_PASSWORD="password"
DB_HOST="localhost"
JWT_SECRET="N5vZ$eJ#8dL4BqV3RfUjPpL9W2xO8vG"

# Redis Configuration
REDIS_PORT=6379
REDIS_HOST="localhost"

# Email Configuration
EMAIL_HOST="neelgiri.iiit.ac.in"
EMAIL_PORT=25

# Log File Path
LOG_DIRECTORY="./logs/"
LOG_LEVEL="debug"
LOG_ROTATION_INTERVAL="daily"    # Can be 'daily', 'weekly', or 'monthly'
LOG_MAX_FILES="30d"              # Set how long to keep old log files

# sendgrid
SENDGRID_API_KEY="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"

# test dummy values
TEST_USER_NAME="aman@ihub-data.iiit.ac.in" # your test email
TEST_USER_ID="3f0e79f0-8c16-4e3e-bc7f-245a853d5eef" # userID from yourdb
TEST_APP_NAME="dfs"
```

## How to Run the Code

### Prerequisites

Before you can run the application, ensure the following prerequisites are installed on your system:

1. **Node.js**: Ensure that Node.js is installed on your system. You can download it from [here](https://nodejs.org/).
2. **MySQL**: You need MySQL installed on your system to manage the `dfsdata_v2` database. You can download it from [here](https://dev.mysql.com/downloads/).
3. **Redis**: The application requires Redis for caching. Follow the respective instructions based on your operating system:
   - **Windows**: Use [this guide](https://redis.io/blog/install-redis-windows-11/) to install Redis on Windows.
   - **Linux**: Use [this guide](https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/install-redis-on-linux/) to install Redis on Linux.

### Installation of Prerequisites

1. **Install Node.js**: Download and install Node.js from the official site based on your OS.
   - Verify the installation by running:
     ```bash
     node -v
     ```

2. **Install MySQL**: Download and install MySQL. Ensure that the MySQL server is running.
   - Verify MySQL installation by running:
     ```bash
     mysql -u root -p
     ```

3. **Install Redis**: Based on your OS, follow the instructions mentioned above to install Redis.

### Database Setup

Before starting the application, make sure the following steps are completed:

1. **Database Creation**: Ensure that the `dfsdata_v2` database exists in your MySQL setup. You can create it manually by running the following command in MySQL:
   ```sql
   CREATE DATABASE dfsdata_v2;
   ```
   The application will automatically create the necessary tables inside this database when it runs.

2. **Trigger Setup**: Navigate to the `models/authorization/` folder of DFS backend project. In this folder, there is a file named `dfs_role_permission_trigger.sql`. This file contains SQL code to create a trigger automatically updates the `role_permission` table when entries are added or deleted (soft deletion) in the `roles` or `permissions` tables. Execute this SQL script in MySQL by running:
   ```bash
   mysql -u root -p dfsdata_v2 < models/authorization/dfs_role_permission_trigger.sql
   ```
   This will create a trigger that automatically updates the `role_permission` table whenever entries in the `roles` or `permissions` tables are added or soft deleted.

### Pre-filled Database Information

To ensure that authorization works correctly, make sure that some essential entries are present in the `roles` and `permissions` tables. These tables will be used for role-based access control in your application.

**Sample `roles` table entry**:
```sql
INSERT INTO roles (role_id, role_key, role_name, role_description, isActive, createdAt, updatedAt)
VALUES ('aab42de4-70bf-447c-b128-5f44aa77007b', 'default_user', 'Default User', 'NA', '1', '2024-10-08 15:49:44', '2024-10-08 15:49:44');
```

**Sample `permissions` table entry**:
```sql
INSERT INTO permissions (permission_id, permission_key, permission_name, description, isActive, createdAt, updatedAt)
VALUES ('f5c05fb9-67be-4345-9a5f-f8d17c450ea6', 'create_new_role', 'Create New Role', 'NA', '1', '2024-10-08 15:50:52', '2024-10-08 15:50:52');
```

### Running the Application

Once all the prerequisites are set up and the necessary steps are completed, follow these steps to start the server:

1. Install the dependencies:
   ```bash
   npm install
   ```

2. Run the server:
   ```bash
   node server.js
   ```
   The application will run on **port 3001** by default. Open your browser and navigate to `http://localhost:3001`.

3. 

### Additional Notes

- Ensure that the Redis server is running before starting the application.
- The Node.js app automatically handles table creation, so manual setup of tables beyond the database and trigger script is not required.

## API Documentation

To view the API documentation for this application, you can use Swagger UI. Swagger provides an interactive interface to explore and test the endpoints available in your API.

### Accessing Swagger Docs

To access the Swagger documentation, open your web browser and navigate to:

```
http://<your-server-address>/api-docs/
```

Replace `<your-server-address>` with the address where your Node.js application is hosted. If you are running the application locally, you can use:

```
http://localhost:3001/api-docs/
```

### Features of the Swagger UI

- **Interactive Testing:** You can test API endpoints directly from the documentation interface.
- **Detailed Descriptions:** Each endpoint includes detailed information about its parameters, request and response formats, and possible status codes.
- **Response Examples:** View example responses for various scenarios to understand the data returned by the API.

Make sure your server is running and properly configured to serve the Swagger documentation. If you encounter any issues, check the application logs for errors related to Swagger.

### Middleware: `validateAccessToken`

The `validateAccessToken` middleware is responsible for verifying access tokens in incoming requests. It checks for the presence of an access token in the request headers or cookies and verifies its validity. If the token is missing or invalid, the middleware throws an error.

#### Token Validation Bypass in Test Environment

To facilitate testing, the `validateAccessToken` middleware behaves differently when the environment type is set to `test` in the `.env` file. 

- **Environment Variable**: The `ENV_TYPE` variable in the `.env` file controls the environment mode.  
- **Value**: Set `ENV_TYPE=test` to enable bypass mode.

When `ENV_TYPE` is set to `test`, token validation is bypassed, and the middleware assigns dummy values to the request, allowing the application to run seamlessly without requiring a valid access token.

The following environment variables are used as dummy values in the test environment:

    TEST_USER_NAME: Test user’s email (default: "aman@test.com")
    TEST_USER_ID: Test user’s ID (default: "3f0e79f0-8c16-4e3e-bc7f-245a853d5eef")
    TEST_APP_NAME: Test application name (default: "dfs")


These values are only applied when `ENV_TYPE` is `test`, ensuring regular access token verification in other environments.


# Database Schema

The application uses a MySQL database, which will automatically create the required tables on running the app. Below is the schema for each table along with the sample insert queries.

## Tables Overview

### 1. `roles` Table

| Column           | Type        | Description                                    |
|------------------|-------------|------------------------------------------------|
| `role_id`        | VARCHAR(36) | UUID for role_id (Primary Key)                 |
| `role_key`       | VARCHAR(255)| Unique key for the role                        |
| `role_name`      | VARCHAR(255)| Name of the role                               |
| `role_description`| TEXT       | Description of the role                        |
| `isActive`       | TINYINT(1)  | Soft delete flag (1 = active, 0 = soft deleted)|
| `createdAt`      | DATETIME    | Timestamp when the role was created            |
| `updatedAt`      | DATETIME    | Timestamp when the role was last updated       |

**Sample Insert Query**:
```sql
INSERT INTO roles (role_id, role_key, role_name, role_description, isActive, createdAt, updatedAt)
VALUES ('aab42de4-70bf-447c-b128-5f44aa77007b', 'default_user', 'Default User', 'NA', 1, '2024-10-08 15:49:44', '2024-10-08 15:49:44');
```

### 2. `permissions` Table

| Column              | Type        | Description                                    |
|---------------------|-------------|------------------------------------------------|
| `permission_id`     | VARCHAR(36) | UUID for permission_id (Primary Key)           |
| `permission_key`    | VARCHAR(255)| Unique key for the permission                  |
| `permission_name`   | VARCHAR(255)| Name of the permission                         |
| `description`       | TEXT        | Description of the permission                  |
| `isActive`          | TINYINT(1)  | Soft delete flag (1 = active, 0 = soft deleted)|
| `createdAt`         | DATETIME    | Timestamp when the permission was created      |
| `updatedAt`         | DATETIME    | Timestamp when the permission was last updated |

**Sample Insert Query**:
```sql
INSERT INTO permissions (permission_id, permission_key, permission_name, description, isActive, createdAt, updatedAt)
VALUES ('f5c05fb9-67be-4345-9a5f-f8d17c450ea6', 'create_new_role', 'Create New Role', 'NA', 1, '2024-10-08 15:50:52', '2024-10-08 15:50:52');
```

### 3. `role_permission` Table

| Column              | Type        | Description                                        |
|---------------------|-------------|----------------------------------------------------|
| `role_permission_id`| VARCHAR(36) | UUID for role_permission_id (Primary Key)          |
| `role_id`           | VARCHAR(36) | Foreign key to `roles` table                       |
| `permission_id`     | VARCHAR(36) | Foreign key to `permissions` table                 |
| `value`             | TINYINT(1)  | Boolean value representing permission (1 = true)   |
| `isActive`          | TINYINT(1)  | Soft delete flag (1 = active, 0 = soft deleted)    |
| `createdAt`         | DATETIME    | Timestamp when the role_permission was created     |
| `updatedAt`         | DATETIME    | Timestamp when the role_permission was last updated|

**Sample Insert Query**:
```sql
INSERT INTO role_permission (role_permission_id, role_id, permission_id, value, isActive, createdAt, updatedAt)
VALUES ('d6f67e1f-28c1-4e8f-94b4-ecfbad2a7568', 'aab42de4-70bf-447c-b128-5f44aa77007b', 'f5c05fb9-67be-4345-9a5f-f8d17c450ea6', 1, 1, '2024-10-08 15:52:00', '2024-10-08 15:52:00');
```

### 4. `users` Table

| Column             | Type         | Description                                    |
|--------------------|--------------|------------------------------------------------|
| `user_id`          | STRING       | UUID for user_id (Primary Key)                 |
| `username`         | VARCHAR(255) | Unique username                                |
| `firstname`        | VARCHAR(255) | User's first name                              |
| `lastname`         | VARCHAR(255) | User's last name                               |
| `organization_name`| VARCHAR(255) | Organization name                              |
| `designation`      | VARCHAR(255) | Designation of the user                        |
| `user_role`        | STRING       | Role of the user (references `role_id` in `roles` table) |
| `isActive`         | BOOLEAN      | Soft delete flag (1 = active, 0 = soft deleted)|
| `created_at`       | TIMESTAMP    | Timestamp when the user was created            |
| `updated_at`       | TIMESTAMP    | Timestamp when the user was last updated       |

**Sample Insert Query**:
```sql
INSERT INTO users (user_id, username, firstname, lastname, organization_name, designation, user_role, isActive, created_at, updated_at)
VALUES ('123e4567-e89b-12d3-a456-426614174000', 'aman.khandelwal@gmail.com', 'Aman', 'Khandelwal', 'IHub-Data', 'Developer', 'aab42de4-70bf-447c-b128-5f44aa77007b', 1, '2024-10-08 16:00:00', '2024-10-08 16:00:00');
```

### 5. `user_details` Table

| Column                            | Type         | Description                                      |
|-----------------------------------|--------------|--------------------------------------------------|
| `user_id`                         | STRING       | UUID for user_id (Primary Key)                   |
| `user_tag_line`                   | VARCHAR(255) | User's tag line                                  |
| `user_pronouns`                   | VARCHAR(50)  | User's pronouns                                  |
| `user_organization_mailid`        | VARCHAR(255) | User's organizational email ID (Unique)          |
| `user_profile_image`              | VARCHAR(255) | URL to the user's profile image                  |
| `user_organization_mail_verification_status` | BOOLEAN | Verification status of organizational email      |
| `user_privileged_access`          | BOOLEAN      | Whether the user has privileged access           |
| `user_profile_url`                | VARCHAR(255) | URL to the user's profile                        |
| `isActive`                        | BOOLEAN      | Soft delete flag (1 = active, 0 = soft deleted)  |
| `created_at`                      | TIMESTAMP    | Timestamp when the details were created          |
| `updated_at`                      | TIMESTAMP    | Timestamp when the details were last updated     |

**Sample Insert Query**:
```sql
INSERT INTO user_details (user_id, user_tag_line, user_pronouns, user_organization_mailid, user_profile_image, user_organization_mail_verification_status, user_privileged_access, user_profile_url, isActive, created_at, updated_at)
VALUES ('123e4567-e89b-12d3-a456-426614174000', 'Software Developer at Example Corp', 'he/him', 'aman.khandelwal@gmail.com', '/images/profile.jpg', FALSE, FALSE, 'https://example.com/aman', TRUE, '2024-10-08 16:05:00', '2024-10-08 16:05:00');
```

# DFS - Project Requirements

## Overview

The Data Foundation will host a library of digital data, and will encompass the technology-platform, infrastructure and manpower to collect, create, curate, annotate, secure and deploy it. It will be a major resource for the technology community, researchers and application developers who need such data for developing solutions driven by AI and analytics in socially-relevant domains such as Healthcare, Mobility, Buildings, Systems, and their application in the Indian context.

State of art technology in data analytics and AI available nationally and globally has proven its capabilities and benefits in several domains. Yet, critical gaps remain, as they require large, curated datasets, annotated specifically for each domain problem that needs to be addressed. Identifying and solving the problems that will streamline the building of valuable datasets is a critical need of the day. Some interesting and difficult challenges that present themselves in this context are described below.


## System Requirements

The project's web interface is mostly based on javascript. The backend is created in Node.js framework. Nodejs is used for server-side programming, and primarily deployed for non-blocking, event-driven servers, such as traditional web sites and back-end API services.

The UI is createdusing ReactJS. 
The React.js framework is an open-source JavaScript framework and library developed by Facebook. It's used for building interactive user interfaces and web applications quickly and efficiently with significantly less code than you would with vanilla JavaScript.

MYSQL database is used for storing the data

The uploading and downloading of the data will involve
MinIO. Minio is an open source distributed object storage server written in Go, designed for Private Cloud infrastructure providing S3 storage functionality. It is the best server which is suited for storing unstructured data such as photos, videos, log files, backups, and container.